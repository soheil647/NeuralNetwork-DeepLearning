{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoGAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xH_YlVcUfgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import zeros, ones, expand_dims, hstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Activation\n",
        "from matplotlib import pyplot\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh5a6BQbdohB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "9ec76e25-fe51-45fc-9b9d-4343f48efffd"
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oZ7UH4VrR8P",
        "colab_type": "text"
      },
      "source": [
        "## define discriminator model\n",
        "there is 3 Conv layers followed by 1 dense layer to determine fake or realness <br>\n",
        "to Create Q_model to calculate regularization term of new latent code we added 1 new 128 dimention Dense and 1 n_cat (information we are going to learn for images) dimentinal Dense layer with softmax\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C0O4ftSaN1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the standalone discriminator model\n",
        "def define_discriminator(n_cat, in_shape=(32,32,3)):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # image input\n",
        "  in_image = Input(shape=in_shape)\n",
        "  # downsample to 16x16\n",
        "  d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
        "  d = LeakyReLU(alpha=0.1)(d)\n",
        "  print(d.shape)\n",
        "  # downsample to 8x8\n",
        "  d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "  d = LeakyReLU(alpha=0.1)(d)\n",
        "  d = BatchNormalization()(d)\n",
        "  # normal\n",
        "  d = Conv2D(256, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "  d = LeakyReLU(alpha=0.1)(d)\n",
        "  d = BatchNormalization()(d)\n",
        "  # flatten feature maps\n",
        "  d = Flatten()(d)\n",
        "  # real/fake output\n",
        "  out_classifier = Dense(1, activation='sigmoid')(d)\n",
        "  # define d model\n",
        "  d_model = Model(in_image, out_classifier)\n",
        "  # compile d model\n",
        "  d_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "  # create q model layers\n",
        "  q = Dense(128)(d)\n",
        "  q = BatchNormalization()(q)\n",
        "  q = LeakyReLU(alpha=0.1)(q)\n",
        "  # q model output\n",
        "  out_codes = Dense(n_cat, activation='softmax')(q)\n",
        "  # define q model\n",
        "  q_model = Model(in_image, out_codes)\n",
        "  return d_model, q_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4ngS5NFtTfT",
        "colab_type": "text"
      },
      "source": [
        "## Define Generator\n",
        "Relatively to discriminator we have 1 Dense layer followed by 1 Conv layer and used 2 Transpose Conv layer to up sample and to create new images from 2 latent input (noise and code)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ_yIhchaQE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the standalone generator model\n",
        "def define_generator(gen_input_size):\n",
        "  # weight initialization\n",
        "  init = RandomNormal(stddev=0.02)\n",
        "  # image generator input\n",
        "  in_lat = Input(shape=(gen_input_size,))\n",
        "  # foundation for 8x8 image\n",
        "  n_nodes = 512 * 8 * 8\n",
        "  gen = Dense(n_nodes, kernel_initializer=init)(in_lat)\n",
        "  gen = Activation('relu')(gen)\n",
        "  gen = BatchNormalization()(gen)\n",
        "  gen = Reshape((8, 8, 512))(gen)\n",
        "  # normal\n",
        "  gen = Conv2D(128, (4,4), padding='same', kernel_initializer=init)(gen)\n",
        "  gen = Activation('relu')(gen)\n",
        "  gen = BatchNormalization()(gen)\n",
        "  # upsample to 16x16\n",
        "  gen = Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
        "  gen = Activation('relu')(gen)\n",
        "  gen = BatchNormalization()(gen)\n",
        "  # upsample to 32x32\n",
        "  gen = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
        "  # tanh output\n",
        "  out_layer = Activation('tanh')(gen)\n",
        "  # define model\n",
        "  model = Model(in_lat, out_layer)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEkVl6OqtpIm",
        "colab_type": "text"
      },
      "source": [
        "## Define InfoGAN\n",
        "here we create discriminator q and generator model and compile them with Adam optimizer and 0.0002 learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cncfz16PaSXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the combined discriminator, generator and q network model\n",
        "def define_gan(g_model, d_model, q_model):\n",
        "  # make weights in the discriminator (some shared with the q model) as not trainable\n",
        "  d_model.trainable = False\n",
        "  # connect g outputs to d inputs\n",
        "  d_output = d_model(g_model.output)\n",
        "  # connect g outputs to q inputs\n",
        "  q_output = q_model(g_model.output)\n",
        "  # define composite model\n",
        "  model = Model(g_model.input, [d_output, q_output])\n",
        "  # compile model\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n",
        "  print(model.summary)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPbF7zqQtzJk",
        "colab_type": "text"
      },
      "source": [
        "## Load Cifar10 Data set and sacel it to [-1,1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaRzruZ7ac4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load images\n",
        "def load_real_samples():\n",
        "\t# load dataset\n",
        "\t(trainX, _), (_, _) = cifar10.load_data()\n",
        "\t# expand to 3d, e.g. add channels\n",
        "\tX = expand_dims(trainX, axis=-1)\n",
        "\t# convert from ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\tprint(X.shape)\n",
        "\treturn X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4lEZgQ8t3b0",
        "colab_type": "text"
      },
      "source": [
        "## Generate real images \n",
        "generate n_sample from dataset which are real images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dob7Tzoiam5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# select images and labels\n",
        "\tX = dataset[ix]\n",
        "\t# generate class labels\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_twuPsut_Rl",
        "colab_type": "text"
      },
      "source": [
        "## Generate latent points\n",
        "Generate latent point from 2 inputs spaces (noise and code)<br>\n",
        "then these latent poing will be given to Generator model to produce new images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_eWdcZIapLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_cat, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tz_latent = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tz_latent = z_latent.reshape(n_samples, latent_dim)\n",
        "\t# generate categorical codes\n",
        "\tcat_codes = randint(0, n_cat, n_samples)\n",
        "\t# one hot encode\n",
        "\tcat_codes = to_categorical(cat_codes, num_classes=n_cat)\n",
        "\t# concatenate latent points and control codes\n",
        "\tz_input = hstack((z_latent, cat_codes))\n",
        "\treturn [z_input, cat_codes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05tAlfb5uONn",
        "colab_type": "text"
      },
      "source": [
        "## Fake sample generator\n",
        "Generator then predict from these latent points and generate new samples that are fake and differs from real ones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RvHCJ0qarCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_cat, n_samples):\n",
        "\t# generate points in latent space and control codes\n",
        "\tz_input, _ = generate_latent_points(latent_dim, n_cat, n_samples)\n",
        "\t# predict outputs\n",
        "\timages = generator.predict(z_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn images, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amhvf0C8uaw9",
        "colab_type": "text"
      },
      "source": [
        "## Plot and save\n",
        "we save our images and models every epoch in case of disconnectivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHQOQATVatd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, gan_model, latent_dim, n_cat, n_samples=100):\n",
        "\t# prepare fake examples\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_cat, n_samples)\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(100):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(10, 10, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(X[i, :, :, 0])\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'images/%d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model/%d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\t# save the gan model\n",
        "\tfilename3 = 'gan_model/%d.h5' % (step+1)\n",
        "\tgan_model.save(filename3)\n",
        "\tprint('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-V4QGM5uilF",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "here for each epoch and for each image in batch size which is 64 we generate real and fake images and predict their validity with discriminator<br>\n",
        "we take points from latent spaces and feed them to generator and made it to produce new images then we compute its loss and update weights to lear our network <br>\n",
        "after some epoches we get better images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6QG3kKCaxtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_cat, n_epochs=20, n_batch=64):\n",
        "\n",
        "  d1_loss_history = []\n",
        "  d2_loss_history = []\n",
        "  g1_loss_history = []\n",
        "  g2_loss_history = []\n",
        "\n",
        "  # calculate the number of batches per training epoch\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "  # calculate the number of training iterations\n",
        "  n_steps = bat_per_epo * n_epochs\n",
        "  # calculate the size of half a batch of samples\n",
        "  half_batch = int(n_batch / 2)\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_steps):\n",
        "    # get randomly selected 'real' samples\n",
        "    X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "    # update discriminator and q model weights\n",
        "    d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
        "    # generate 'fake' examples\n",
        "    X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_cat, half_batch)\n",
        "    # update discriminator model weights\n",
        "    d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "    # prepare points in latent space as input for the generator\n",
        "    z_input, cat_codes = generate_latent_points(latent_dim, n_cat, n_batch)\n",
        "    # create inverted labels for the fake samples\n",
        "    y_gan = ones((n_batch, 1))\n",
        "    # update the g via the d and q error\n",
        "    _,g_1,g_2 = gan_model.train_on_batch(z_input, [y_gan, cat_codes])\n",
        "    # summarize loss on this batch\n",
        "    print('>%d, d[%.3f,%.3f], g[%.3f] q[%.3f]' % (i+1, d_loss1, d_loss2, g_1, g_2))\n",
        "    d1_loss_history.append(d_loss1)\n",
        "    d2_loss_history.append(d_loss2)\n",
        "    g1_loss_history.append(g_1)\n",
        "    g2_loss_history.append(g_2)\n",
        "    # evaluate the model performance every 'epoch'\n",
        "    if (i+1) % (bat_per_epo * 10) == 0:\n",
        "      summarize_performance(i, g_model, gan_model, latent_dim, n_cat)\n",
        "  return d1_loss_history, d2_loss_history, g1_loss_history, g2_loss_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5s_2EZCaz6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "1bb797b2-d7de-413b-bb22-d6bf27890f24"
      },
      "source": [
        "# number of values for the categorical control code\n",
        "n_cat = 10\n",
        "# size of the latent space\n",
        "latent_dim = 62\n",
        "# create the discriminator\n",
        "d_model, q_model = define_discriminator(n_cat)\n",
        "# create the generator\n",
        "gen_input_size = latent_dim + n_cat\n",
        "g_model = define_generator(gen_input_size)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model, q_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "d1_loss_history, d2_loss_history, g1_loss_history, g2_loss_history = train(g_model, d_model, gan_model, dataset, latent_dim, n_cat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 16, 16, 64)\n",
            "<bound method Model.summary of <tensorflow.python.keras.engine.functional.Functional object at 0x7fea33223128>>\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3, 1)\n",
            ">1, d[1.192,0.736], g[0.692] q[2.319]\n",
            ">2, d[0.400,0.490], g[0.693] q[2.324]\n",
            ">3, d[0.070,0.318], g[0.695] q[2.253]\n",
            ">4, d[0.076,0.226], g[0.697] q[2.263]\n",
            ">5, d[0.060,0.124], g[0.699] q[2.292]\n",
            ">6, d[0.035,0.097], g[0.700] q[2.210]\n",
            ">7, d[0.029,0.075], g[0.701] q[2.266]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e3b0b263b89f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0md1_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg1_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-651040df4591>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, gan_model, dataset, latent_dim, n_cat, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0my_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# update the g via the d and q error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_gan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_codes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# summarize loss on this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>%d, d[%.3f,%.3f], g[%.3f] q[%.3f]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdmazFWuHteU",
        "colab_type": "text"
      },
      "source": [
        "## Plot loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UFijmmvDBtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_parameter(input, title)\n",
        "  pyplot.plot(input)\n",
        "  pyplot.title(title)\n",
        "  pyplot.xlabel('Epoch')\n",
        "  pyplot.ylabel('loss')\n",
        "  pyplot.show()\n",
        "plot_parameter(d1_loss_history, \"d1_loss\")\n",
        "plot_parameter(d2_loss_history, 'd2_loss')\n",
        "plot_parameter(g1_loss_history, 'g1_loss')\n",
        "plot_parameter(g2_loss_history, 'g2_loss')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}